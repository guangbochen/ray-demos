{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14cab54",
   "metadata": {},
   "source": [
    "# A Guided Tour of Ray Core: Remote Tasks\n",
    "\n",
    "¬© 2019-2023, Anyscale. All Rights Reserved\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ray enables arbitrary Python functions to be executed asynchronously on separate Python workers. These asynchronous Ray functions are called ‚Äútasks.‚Äù You can specify task's resource requirements in terms of CPUs, GPUs, and custom resources. These resource requests are used by the cluster scheduler to distribute tasks across the cluster for parallelized execution.  \n",
    "\n",
    "|<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Ray_Core/python_to_ray_concept_map.png\" height=\"55%\">|\n",
    "|:--|\n",
    "|Transforming Python code into Ray Tasks, Actors, and Immutable Ray objects.|\n",
    "\n",
    "|<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Ray_Core/python_to_ray_task_map.png\" height=\"55%\">|\n",
    "|:--|\n",
    "|Transforming Python function into Ray Tasks|\n",
    "\n",
    "## Learning objectives\n",
    "In this this tutorial, you'll learn about:\n",
    " * Remote Task Parallel Pattern\n",
    " * Stateless remote functions as distributed tasks\n",
    " * Serial vs Parallel execution \n",
    " * Understand the concept of a Ray task \n",
    " * Easy API to convert an existing Python function into a Ray remote task\n",
    " * Walk through examples comparing serial vs. distributed Python functions and Ray tasks respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee29917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import tqdm\n",
    "import ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b98b39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tasks Parallel Pattern\n",
    "\n",
    "Ray converts decorated functions with `@ray.remote` into stateless tasks, scheduled anywhere on a Ray node's worker in the cluster. \n",
    "\n",
    "Where they will be executed on the cluster (and on what node by which worker process), you don't have to worry about its details. All that is taken care for you. Nor do \n",
    "you have to reason about it ‚Äî all that burden is Ray's job. You simply take your existing Python functions and covert them into \n",
    "distributed stateless *Ray Tasks*: **as simple as that!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ec22c",
   "metadata": {},
   "source": [
    "### Serial vs Parallelism Execution\n",
    "\n",
    "Serial tasks as regular Python functions are executed in a sequential manner, as shown\n",
    "in the diagram below. If I launch ten tasks, they will run on a single worker, one after the other.\n",
    " \n",
    "|<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Overview_of_Ray/sequential_timeline.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Timeline of sequential tasks, one after the other.|\n",
    "\n",
    "Compared to serial execution, a Ray task executes in parallel, scheduled on different workers. The Raylet will schedule these task based on [scheduling policies.](https://docs.ray.io/en/latest/ray-core/scheduling/index.html#ray-scheduling-strategies)\n",
    "\n",
    "|<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Overview_of_Ray/distributed_timeline.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Sample timeline with ten tasks running across 4 worker nodes in parallel.|\n",
    "\n",
    "Let's look at some tasks running serially and then in parallel. For illustration, we'll use a the following tasks:\n",
    " * Generating fibonacci numbers serially and distributed\n",
    " * Computing value of pi using the monte carlo method\n",
    " * Transforming and processing large high-resolution images\n",
    " * Doing batch inference using Ray tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a44dfe",
   "metadata": {},
   "source": [
    "But first, some basic concepts: There are a few key differences between an original Python function and the decorated one:\n",
    "\n",
    "**Invocation**: The regular version is called with `func_name()`, whereas the remote Ray version is called with `func_name.remote()`. Keep this pattern in mind for all Ray remote execution methods.\n",
    "\n",
    "**Mode of execution and return values**: A Python `func_name()` executes synchronously and returns the result of the function, whereas a Ray task `func_name.remote()` immediately returns an `ObjectRef` (a future) and then executes the task in the background on a remote worker process. \n",
    "\n",
    "The result of the future is obtained by calling `ray.get(ObjectRef)` on the `ObjectRef`. This is a blocking function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04aec4",
   "metadata": {},
   "source": [
    "Let's launch a Ray cluster on our local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eeba1a",
   "metadata": {},
   "source": [
    "## Example: Generating Fibonnaci series\n",
    "\n",
    "Let's define two functions: one runs serially, the other runs on a Ray cluster (local or remote). This example is borrowed and refactored from our \n",
    "blog: [Writing your First Distributed Python Application with Ray](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray). \n",
    "(This is an excellent tutorial to get started with the concept of why and when to use Ray tasks and Ray Actors. Highly recommended read!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb49fa-00c0-4994-bd74-2d1093ff5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_SIZE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49994253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for local execution \n",
    "def generate_fibonacci(sequence_size):\n",
    "    fibonacci = []\n",
    "    for i in range(0, sequence_size):\n",
    "        if i < 2:\n",
    "            fibonacci.append(i)\n",
    "            continue\n",
    "        fibonacci.append(fibonacci[i-1]+fibonacci[i-2])\n",
    "    return len(fibonacci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92777c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for remote Ray task with just a wrapper\n",
    "@ray.remote\n",
    "def generate_fibonacci_distributed(sequence_size):\n",
    "    return generate_fibonacci(sequence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of cores \n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Python in a single process \n",
    "def run_local(sequence_size):\n",
    "    results = [generate_fibonacci(sequence_size) for _ in range(os.cpu_count())]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a917b1-7af2-4729-8b93-39883fc5054e",
   "metadata": {},
   "source": [
    "### Run in serial mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_local(SEQUENCE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc510e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed on a Ray cluster\n",
    "def run_remote(sequence_size):\n",
    "    results = ray.get([generate_fibonacci_distributed.remote(sequence_size) for _ in range(os.cpu_count())])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda02ce-cafd-4183-b36c-6aa28234cdf4",
   "metadata": {},
   "source": [
    "### Run as distributed Ray tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_remote(SEQUENCE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcecd59-8b2c-4983-acc1-9572ba04590e",
   "metadata": {},
   "source": [
    "### Recap\n",
    "As you can see that running as Ray Tasks, we see a significant performance improvment\n",
    "üìà by simply adding a Python decorator `ray.remote(...)`.\n",
    "\n",
    "To see how different values of computing Fibonnacci number affects the serial vs. performance execution times, try the exercise below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
